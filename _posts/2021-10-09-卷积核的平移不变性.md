---
title: CNN的equivariant和invariant
tags: 深度学习 基础概念 
---

个人觉得CNN具有的应该是平移不变性（equivariant），即使输入的特征在空间位置上发生了偏移，但是卷积核函数在偏移后的位置上计算得到的结果仍然保持不变。这与目标检测任务的需求是相符的。
至于平移不变性则应该是池化层带来的，池化函数将不同的局部信息混合后得到一个全局的特征，即使局部位置上发生了便宜，输出仍然也会保持不变，因此对于分类任务来说，池化往往是必须的，
卷积只是用来提取局部的特征。

此外在特定的卷积核函数下，CNN可能还会具有一定的旋转不变性、平移不变性还是缩放不变性。
