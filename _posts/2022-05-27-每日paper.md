---
layout: post
title: 每日工作学习记录
tags: paper
---

## ✈️ 2022-05

#### 🐯 *2022-05-27*

##### 🍉 arXiv Paper
  - [Fast Vision Transformers with HiLo Attention ](https://arxiv.org/pdf/2205.13213.pdf) <br>关键词：*Transformer, Attention*
  - [MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning](https://arxiv.org/pdf/2205.13137.pdf) <br>关键词：*自监督学习, Masked Image Modeling*
  - [HIRL: A General Framework for Hierarchical Image Representation Learning](https://arxiv.org/pdf/2205.13159.pdf)<br>关键词： *Hierarchical 层级语义表征学习*
  - [SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation](https://arxiv.org/pdf/2205.13490.pdf)<br>关键词：*3D点云分割, 语义仿射变换*
  - [AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition](https://arxiv.org/pdf/2205.13535.pdf)<br>关键词：*Transformer*
  - [Revealing the Dark Secrets of Masked Image Modeling](https://arxiv.org/pdf/2205.13543.pdf)<br>关键词： *解释 Masked Image Modeling*

🍉 工作内容与进展
  - 旷视实习

🍉 感触
  - 当前改进`Vision Transformer`的工作热度还是很高。

🌙 🌙 🌙 

---

🐯 *2022-05-28*


---

🐯 *2022-05-29*

---

🐯 *2022-06-01*

##### 🍉 arXiv Paper

- [GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector](https://arxiv.org/pdf/2205.15469.pdf)<br>关键词：Co-Salient 目标检测 

- [What Knowledge Gets Distilled in Knowledge Distillation?](https://arxiv.org/pdf/2205.16004.pdf)<br>关键词：知识蒸馏

- [Self-Supervised Visual Representation Learning with Semantic Grouping](https://arxiv.org/pdf/2205.15288.pdf)<br>关键词：自监督学习 语义分组 <br>感觉自己对自监督学习这块的工作有点脸盲，不是很好地鉴别其创新的地方到底在哪？？

- [Rethinking Spatial Dimensions of Vision Transformers](https://arxiv.org/pdf/2103.16302.pdf)<br>关键词：Transformer<br>其实是2021-ICCV的工作了，这里也把挂出来方便以后学习查阅。

- [FP-DETR: Detection Transformer Advanced by Fully Pre-training](https://openreview.net/pdf?id=yjMQuLLcGWK)<br>关键词: Transformer,  Detection, 预训练

##### 🍉 代码开源 


- [CCAM: Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation 代码开源](https://github.com/CVI-SZU/CCAM/tree/master/WSOL)

- [CLIMS: Cross Language Image Matching for Weakly Supervised Semantic Segmentation 代码开源](https://github.com/CVI-SZU/CLIMS)

🍉 工作内容与进展

  - 旷视实习这边的工作进展不高，很丧...
  - 简单跑了下 [CCAM源码](https://github.com/CVI-SZU/CCAM/tree/master/WSOL)， 很简单的工作，work 程度也一般吧，不过idea比较新颖。
  - 最近需要准备下IJCAI2022的 presentation，以及中期答辩材料。
  

🍉 感触
  - 自律自强

---

🐯 *2022-06-03*

##### 🍉 arXiv Paper

- [Siamese Image Modeling for Self-Supervised Vision Representation Learning](https://arxiv.org/pdf/2206.01204.pdf)<br>关键词：自监督学习

- [Semantic Instance Segmentation of 3D Scenes Through Weak Bounding Box Supervision](https://arxiv.org/pdf/2206.01203.pdf)<br>关键词：3D弱监督学习

- [Unveiling The Mask of Position-Information Pattern Through the Mist of Image Features](https://arxiv.org/pdf/2206.01202.pdf)<br>关键词：
  
- [Optimizing Relevance Maps of Vision Transformers Improves Robustness](https://arxiv.org/pdf/2206.01161.pdf)<br>关键词： Transformers


- [VL-BEIT: Generative Vision-Language Pretraining](https://arxiv.org/pdf/2206.01127.pdf)<br>关键词：视觉-语言预训练


- [Prefix Conditioning Unifies Language and Label Supervision](https://arxiv.org/pdf/2206.01125.pdf) <br>关键词：预训练

- [Where are my Neighbors? Exploiting Patches Relations in Self-Supervised Vision Transformer](https://arxiv.org/pdf/2206.00481.pdf)<br> 关键词：Transformer

🍉 工作内容与进展



🍉 感触
  - 都在大规模预训练。。。。这玩意到底能走多远？有多少潜力呢？
  - 卷起来

🍉 计划与安排

- 阅读 [Domain Adaptive Semantic Segmentation With Self-Supervised Depth Estimation](https://openaccess.thecvf.com/content/ICCV2021/html/Wang_Domain_Adaptive_Semantic_Segmentation_With_Self-Supervised_Depth_Estimation_ICCV_2021_paper.html)
- 学习 [timm 的模型构造函数](https://blog.csdn.net/weixin_44966641/article/details/121364784)

----

🐯 *2022-06-09*

##### 🍉 arXiv Paper

- [NeurIPS_2022_在投 Towards Understanding Why Mask-Reconstruction Pretraining Helps in Downstream Tasks](https://arxiv.org/pdf/2206.03826.pdf)

##### 🍉 工作内容与进展

- 醉了，深度估计工作价值不高，语义相关性嘛，还在努力探索。

##### 🍉 计划与安排

- 了解一些语义相关性特别是弱监督语义相关性的工作

- [CVPR_2018 End-to-end weakly-supervised semantic alignment](https://arxiv.org/pdf/1712.06861.pdf)
- [ECCV_2020 DHPF: Learning to Compose Hypercolumns for Visual Correspondence](https://arxiv.org/pdf/2007.10587.pdf)
- [ICCV_2021 DISCOBOX: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision](https://openaccess.thecvf.com/content/ICCV2021/papers/Lan_DiscoBox_Weakly_Supervised_Instance_Segmentation_and_Semantic_Correspondence_From_Box_ICCV_2021_paper.pdf)

---

🐯 *2022-06-14*

##### 🍉 arXiv Paper

- [NeurIPS_2022在投Discovering Object Masks with Transformers for Unsupervised Semantic Segmentation](https://arxiv.org/pdf/2206.06363.pdf)
- [NeurIPS_2022在投EnergyMatch: Energy-based Pseudo-Labeling for Semi-Supervised Learning](https://arxiv.org/pdf/2206.06359.pdf)
- [ICML_2022_Learning Domain Adaptive Object Detection with Probabilistic Teacher](https://arxiv.org/pdf/2206.06293.pdf)
- [NeurIPS_2022在投_Featurized Query R-CNN](https://arxiv.org/pdf/2206.06258.pdf)
- [NeurIPS_2022在投_Better Teacher Better Student: Dynamic Prior Knowledge for Knowledge Distillation](https://arxiv.org/pdf/2206.06067.pdf)
- [NeurIPS_2022在投_GLIPv2: Unifying Localization and VL Understanding](https://arxiv.org/pdf/2206.05836.pdf)

##### 🍉 工作内容与进展

- 把IJCAI poster做一下。

---

🐯 *2022-06-16*

##### 🍉 arXiv Paper

- [Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone](https://arxiv.org/pdf/2206.07643.pdf)
- [SP-ViT: Learning 2D Spatial Priors for Vision Transformers](https://arxiv.org/pdf/2206.07662.pdf)
- [Visual Parser: Representing Part-whole Hierarchies with Transformers](https://arxiv.org/pdf/2107.05790.pdf)
- [Masked Siamese ConvNets](https://arxiv.org/pdf/2206.07700.pdf)
- [Masked Frequency Modeling for Self-Supervised Visual Pre-Training](https://arxiv.org/pdf/2206.07706.pdf)
- [Grounded Language-Image Pre-training](https://arxiv.org/abs/2112.03857)

---
  
🐯 *2022-06-20*
##### 🍉 arXiv Paper

- [NeurIPS2022_Under_Review Rectify ViT Shortcut Learning by Visual Saliency](https://arxiv.org/pdf/2206.08567.pdf)
- [ICML_2022_VLMixer: Unpaired Vision-Language Pre-training via Cross-Modal CutMix](https://arxiv.org/pdf/2206.08919.pdf)
- [ECCV_2022_在投_Learning Implicit Feature Alignment Function for Semantic Segmentation](https://arxiv.org/pdf/2206.08655.pdf)
- [ECCV_2022_在投_Cross-task Attention Mechanism for Dense Multi-task Learning](https://arxiv.org/pdf/2206.08927.pdf)
- [BatchFormer: Learning to Explore Sample Relationships for Robust Representation Learning](https://arxiv.org/pdf/2203.01522v2.pdf) [开源代码](https://github.com/zhihou7/BatchFormer)
- [BatchFormerV2:Exploring Sample Relationships for Dense Representation Learning](https://arxiv.org/pdf/2204.01254.pdf)