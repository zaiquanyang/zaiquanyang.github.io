---
layout: post
title: æ¯æ—¥å·¥ä½œå­¦ä¹ è®°å½•
tags: paper
---

## âœˆï¸ 2022-05

#### ğŸ¯ *2022-05-27*

##### ğŸ‰ arXiv Paper
  - [Fast Vision Transformers with HiLo Attention ](https://arxiv.org/pdf/2205.13213.pdf) <br>å…³é”®è¯ï¼š*Transformer, Attention*
  - [MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning](https://arxiv.org/pdf/2205.13137.pdf) <br>å…³é”®è¯ï¼š*è‡ªç›‘ç£å­¦ä¹ , Masked Image Modeling*
  - [HIRL: A General Framework for Hierarchical Image Representation Learning](https://arxiv.org/pdf/2205.13159.pdf)<br>å…³é”®è¯ï¼š *Hierarchical å±‚çº§è¯­ä¹‰è¡¨å¾å­¦ä¹ *
  - [SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation](https://arxiv.org/pdf/2205.13490.pdf)<br>å…³é”®è¯ï¼š*3Dç‚¹äº‘åˆ†å‰², è¯­ä¹‰ä»¿å°„å˜æ¢*
  - [AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition](https://arxiv.org/pdf/2205.13535.pdf)<br>å…³é”®è¯ï¼š*Transformer*
  - [Revealing the Dark Secrets of Masked Image Modeling](https://arxiv.org/pdf/2205.13543.pdf)<br>å…³é”®è¯ï¼š *è§£é‡Š Masked Image Modeling*

ğŸ‰ å·¥ä½œå†…å®¹ä¸è¿›å±•
  - æ—·è§†å®ä¹ 

ğŸ‰ æ„Ÿè§¦
  - å½“å‰æ”¹è¿›`Vision Transformer`çš„å·¥ä½œçƒ­åº¦è¿˜æ˜¯å¾ˆé«˜ã€‚

ğŸŒ™ ğŸŒ™ ğŸŒ™ 

---

ğŸ¯ *2022-05-28*


---

ğŸ¯ *2022-05-29*

---

ğŸ¯ *2022-06-01*

##### ğŸ‰ arXiv Paper

- [GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector](https://arxiv.org/pdf/2205.15469.pdf)<br>å…³é”®è¯ï¼šCo-Salient ç›®æ ‡æ£€æµ‹ 

- [What Knowledge Gets Distilled in Knowledge Distillation?](https://arxiv.org/pdf/2205.16004.pdf)<br>å…³é”®è¯ï¼šçŸ¥è¯†è’¸é¦

- [Self-Supervised Visual Representation Learning with Semantic Grouping](https://arxiv.org/pdf/2205.15288.pdf)<br>å…³é”®è¯ï¼šè‡ªç›‘ç£å­¦ä¹  è¯­ä¹‰åˆ†ç»„ <br>æ„Ÿè§‰è‡ªå·±å¯¹è‡ªç›‘ç£å­¦ä¹ è¿™å—çš„å·¥ä½œæœ‰ç‚¹è„¸ç›²ï¼Œä¸æ˜¯å¾ˆå¥½åœ°é‰´åˆ«å…¶åˆ›æ–°çš„åœ°æ–¹åˆ°åº•åœ¨å“ªï¼Ÿï¼Ÿ

- [Rethinking Spatial Dimensions of Vision Transformers](https://arxiv.org/pdf/2103.16302.pdf)<br>å…³é”®è¯ï¼šTransformer<br>å…¶å®æ˜¯2021-ICCVçš„å·¥ä½œäº†ï¼Œè¿™é‡Œä¹ŸæŠŠæŒ‚å‡ºæ¥æ–¹ä¾¿ä»¥åå­¦ä¹ æŸ¥é˜…ã€‚

- [FP-DETR: Detection Transformer Advanced by Fully Pre-training](https://openreview.net/pdf?id=yjMQuLLcGWK)<br>å…³é”®è¯: Transformer,  Detection, é¢„è®­ç»ƒ

##### ğŸ‰ ä»£ç å¼€æº 


- [CCAM: Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation ä»£ç å¼€æº](https://github.com/CVI-SZU/CCAM/tree/master/WSOL)

- [CLIMS: Cross Language Image Matching for Weakly Supervised Semantic Segmentation ä»£ç å¼€æº](https://github.com/CVI-SZU/CLIMS)

ğŸ‰ å·¥ä½œå†…å®¹ä¸è¿›å±•

  - æ—·è§†å®ä¹ è¿™è¾¹çš„å·¥ä½œè¿›å±•ä¸é«˜ï¼Œå¾ˆä¸§...
  - ç®€å•è·‘äº†ä¸‹ [CCAMæºç ](https://github.com/CVI-SZU/CCAM/tree/master/WSOL)ï¼Œ å¾ˆç®€å•çš„å·¥ä½œï¼Œwork ç¨‹åº¦ä¹Ÿä¸€èˆ¬å§ï¼Œä¸è¿‡ideaæ¯”è¾ƒæ–°é¢–ã€‚
  - æœ€è¿‘éœ€è¦å‡†å¤‡ä¸‹IJCAI2022çš„ presentationï¼Œä»¥åŠä¸­æœŸç­”è¾©ææ–™ã€‚
  

ğŸ‰ æ„Ÿè§¦
  - è‡ªå¾‹è‡ªå¼º

---

ğŸ¯ *2022-06-03*

##### ğŸ‰ arXiv Paper

- [Siamese Image Modeling for Self-Supervised Vision Representation Learning](https://arxiv.org/pdf/2206.01204.pdf)<br>å…³é”®è¯ï¼šè‡ªç›‘ç£å­¦ä¹ 

- [Semantic Instance Segmentation of 3D Scenes Through Weak Bounding Box Supervision](https://arxiv.org/pdf/2206.01203.pdf)<br>å…³é”®è¯ï¼š3Då¼±ç›‘ç£å­¦ä¹ 

- [Unveiling The Mask of Position-Information Pattern Through the Mist of Image Features](https://arxiv.org/pdf/2206.01202.pdf)<br>å…³é”®è¯ï¼š
  
- [Optimizing Relevance Maps of Vision Transformers Improves Robustness](https://arxiv.org/pdf/2206.01161.pdf)<br>å…³é”®è¯ï¼š Transformers


- [VL-BEIT: Generative Vision-Language Pretraining](https://arxiv.org/pdf/2206.01127.pdf)<br>å…³é”®è¯ï¼šè§†è§‰-è¯­è¨€é¢„è®­ç»ƒ


- [Prefix Conditioning Unifies Language and Label Supervision](https://arxiv.org/pdf/2206.01125.pdf) <br>å…³é”®è¯ï¼šé¢„è®­ç»ƒ

ğŸ‰ å·¥ä½œå†…å®¹ä¸è¿›å±•



ğŸ‰ æ„Ÿè§¦
  - éƒ½åœ¨å¤§è§„æ¨¡é¢„è®­ç»ƒã€‚ã€‚ã€‚ã€‚è¿™ç©æ„åˆ°åº•èƒ½èµ°å¤šè¿œï¼Ÿæœ‰å¤šå°‘æ½œåŠ›å‘¢ï¼Ÿ
  - å·èµ·æ¥