---
layout: post
title: æ¯æ—¥å·¥ä½œå­¦ä¹ è®°å½•
tags: paper
---

## âœˆï¸ 2022-05

#### ğŸ¯ *2022-05-27*
ğŸ‰ arXiv Paper
  - [Fast Vision Transformers with HiLo Attention ](https://arxiv.org/pdf/2205.13213.pdf) <br>å…³é”®è¯ï¼š*Transformer, Attention*
  - [MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning](https://arxiv.org/pdf/2205.13137.pdf) <br>å…³é”®è¯ï¼š*è‡ªç›‘ç£å­¦ä¹ , Masked Image Modeling*
  - [HIRL: A General Framework for Hierarchical Image Representation Learning](https://arxiv.org/pdf/2205.13159.pdf)<br>å…³é”®è¯ï¼š *Hierarchical å±‚çº§è¯­ä¹‰è¡¨å¾å­¦ä¹ *
  - [SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation](https://arxiv.org/pdf/2205.13490.pdf)<br>å…³é”®è¯ï¼š*3Dç‚¹äº‘åˆ†å‰², è¯­ä¹‰ä»¿å°„å˜æ¢*
  - [AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition](https://arxiv.org/pdf/2205.13535.pdf)<br>å…³é”®è¯ï¼š*Transformer*
  - [Revealing the Dark Secrets of Masked Image Modeling](https://arxiv.org/pdf/2205.13543.pdf)<br>å…³é”®è¯ï¼š *è§£é‡Š Masked Image Modeling*

ğŸ‰ å·¥ä½œå†…å®¹ä¸è¿›å±•
  - æ—·è§†å®ä¹ 
  -  
ğŸ‰ æ„Ÿè§¦
  - å½“å‰æ”¹è¿›`Vision Transformer`çš„å·¥ä½œçƒ­åº¦è¿˜æ˜¯å¾ˆé«˜ã€‚

ğŸ¯ *2022-05-28*



ğŸ¯ *2022-05-29*