---
layout: post
title: æ¯æ—¥å·¥ä½œå­¦ä¹ è®°å½•
tags: paper
---

## âœˆï¸ 2022-05

#### ğŸ¯ *2022-05-27*

##### ğŸ‰ arXiv Paper
  - [Fast Vision Transformers with HiLo Attention ](https://arxiv.org/pdf/2205.13213.pdf) <br>å…³é”®è¯ï¼š*Transformer, Attention*
  - [MixMIM: Mixed and Masked Image Modeling for Efficient Visual Representation Learning](https://arxiv.org/pdf/2205.13137.pdf) <br>å…³é”®è¯ï¼š*è‡ªç›‘ç£å­¦ä¹ , Masked Image Modeling*
  - [HIRL: A General Framework for Hierarchical Image Representation Learning](https://arxiv.org/pdf/2205.13159.pdf)<br>å…³é”®è¯ï¼š *Hierarchical å±‚çº§è¯­ä¹‰è¡¨å¾å­¦ä¹ *
  - [SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation](https://arxiv.org/pdf/2205.13490.pdf)<br>å…³é”®è¯ï¼š*3Dç‚¹äº‘åˆ†å‰², è¯­ä¹‰ä»¿å°„å˜æ¢*
  - [AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition](https://arxiv.org/pdf/2205.13535.pdf)<br>å…³é”®è¯ï¼š*Transformer*
  - [Revealing the Dark Secrets of Masked Image Modeling](https://arxiv.org/pdf/2205.13543.pdf)<br>å…³é”®è¯ï¼š *è§£é‡Š Masked Image Modeling*

ğŸ‰ å·¥ä½œå†…å®¹ä¸è¿›å±•
  - æ—·è§†å®ä¹ 

ğŸ‰ æ„Ÿè§¦
  - å½“å‰æ”¹è¿›`Vision Transformer`çš„å·¥ä½œçƒ­åº¦è¿˜æ˜¯å¾ˆé«˜ã€‚

ğŸŒ™ ğŸŒ™ ğŸŒ™ 

---

ğŸ¯ *2022-05-28*


---

ğŸ¯ *2022-05-29*

---

ğŸ¯ *2022-06-01*

##### ğŸ‰ arXiv Paper

- [GCoNet+: A Stronger Group Collaborative Co-Salient Object Detector](https://arxiv.org/pdf/2205.15469.pdf)<br>å…³é”®è¯ï¼šCo-Salient ç›®æ ‡æ£€æµ‹ 

- [What Knowledge Gets Distilled in Knowledge Distillation?](https://arxiv.org/pdf/2205.16004.pdf)<br>å…³é”®è¯ï¼šçŸ¥è¯†è’¸é¦

- [Self-Supervised Visual Representation Learning with Semantic Grouping](https://arxiv.org/pdf/2205.15288.pdf)<br>å…³é”®è¯ï¼šè‡ªç›‘ç£å­¦ä¹  è¯­ä¹‰åˆ†ç»„ <br>æ„Ÿè§‰è‡ªå·±å¯¹è‡ªç›‘ç£å­¦ä¹ è¿™å—çš„å·¥ä½œæœ‰ç‚¹è„¸ç›²ï¼Œä¸æ˜¯å¾ˆå¥½åœ°é‰´åˆ«å…¶åˆ›æ–°çš„åœ°æ–¹åˆ°åº•åœ¨å“ªï¼Ÿï¼Ÿ

- [Rethinking Spatial Dimensions of Vision Transformers](https://arxiv.org/pdf/2103.16302.pdf)<br>å…³é”®è¯ï¼šTransformer<br>å…¶å®æ˜¯2021-ICCVçš„å·¥ä½œäº†ï¼Œè¿™é‡Œä¹ŸæŠŠæŒ‚å‡ºæ¥æ–¹ä¾¿ä»¥åå­¦ä¹ æŸ¥é˜…ã€‚

- [FP-DETR: Detection Transformer Advanced by Fully Pre-training](https://openreview.net/pdf?id=yjMQuLLcGWK)<br>å…³é”®è¯: Transformer,  Detection, é¢„è®­ç»ƒ

##### ğŸ‰ ä»£ç å¼€æº 


- [CCAM: Contrastive learning of Class-agnostic Activation Map for Weakly Supervised Object Localization and Semantic Segmentation ä»£ç å¼€æº](https://github.com/CVI-SZU/CCAM/tree/master/WSOL)

- [CLIMS: Cross Language Image Matching for Weakly Supervised Semantic Segmentation ä»£ç å¼€æº](https://github.com/CVI-SZU/CLIMS)

ğŸ‰ å·¥ä½œå†…å®¹ä¸è¿›å±•

  - æ—·è§†å®ä¹ è¿™è¾¹çš„å·¥ä½œè¿›å±•ä¸é«˜ï¼Œå¾ˆä¸§...
  - ç®€å•è·‘äº†ä¸‹ [CCAMæºç ](https://github.com/CVI-SZU/CCAM/tree/master/WSOL)ï¼Œ å¾ˆç®€å•çš„å·¥ä½œï¼Œwork ç¨‹åº¦ä¹Ÿä¸€èˆ¬å§ï¼Œä¸è¿‡ideaæ¯”è¾ƒæ–°é¢–ã€‚
  - æœ€è¿‘éœ€è¦å‡†å¤‡ä¸‹IJCAI2022çš„ presentationï¼Œä»¥åŠä¸­æœŸç­”è¾©ææ–™ã€‚
  

ğŸ‰ æ„Ÿè§¦
  - è‡ªå¾‹è‡ªå¼º

---

ğŸ¯ *2022-06-03*

##### ğŸ‰ arXiv Paper

- [Siamese Image Modeling for Self-Supervised Vision Representation Learning](https://arxiv.org/pdf/2206.01204.pdf)<br>å…³é”®è¯ï¼šè‡ªç›‘ç£å­¦ä¹ 

- [Semantic Instance Segmentation of 3D Scenes Through Weak Bounding Box Supervision](https://arxiv.org/pdf/2206.01203.pdf)<br>å…³é”®è¯ï¼š3Då¼±ç›‘ç£å­¦ä¹ 

- [Unveiling The Mask of Position-Information Pattern Through the Mist of Image Features](https://arxiv.org/pdf/2206.01202.pdf)<br>å…³é”®è¯ï¼š
  
- [Optimizing Relevance Maps of Vision Transformers Improves Robustness](https://arxiv.org/pdf/2206.01161.pdf)<br>å…³é”®è¯ï¼š Transformers


- [VL-BEIT: Generative Vision-Language Pretraining](https://arxiv.org/pdf/2206.01127.pdf)<br>å…³é”®è¯ï¼šè§†è§‰-è¯­è¨€é¢„è®­ç»ƒ


- [Prefix Conditioning Unifies Language and Label Supervision](https://arxiv.org/pdf/2206.01125.pdf) <br>å…³é”®è¯ï¼šé¢„è®­ç»ƒ

- [Where are my Neighbors? Exploiting Patches Relations in Self-Supervised Vision Transformer](https://arxiv.org/pdf/2206.00481.pdf)<br> å…³é”®è¯ï¼šTransformer

ğŸ‰ å·¥ä½œå†…å®¹ä¸è¿›å±•



ğŸ‰ æ„Ÿè§¦
  - éƒ½åœ¨å¤§è§„æ¨¡é¢„è®­ç»ƒã€‚ã€‚ã€‚ã€‚è¿™ç©æ„åˆ°åº•èƒ½èµ°å¤šè¿œï¼Ÿæœ‰å¤šå°‘æ½œåŠ›å‘¢ï¼Ÿ
  - å·èµ·æ¥

ğŸ‰ è®¡åˆ’ä¸å®‰æ’

- é˜…è¯» [Domain Adaptive Semantic Segmentation With Self-Supervised Depth Estimation](https://openaccess.thecvf.com/content/ICCV2021/html/Wang_Domain_Adaptive_Semantic_Segmentation_With_Self-Supervised_Depth_Estimation_ICCV_2021_paper.html)
- å­¦ä¹  [timm çš„æ¨¡å‹æ„é€ å‡½æ•°](https://blog.csdn.net/weixin_44966641/article/details/121364784)

----

ğŸ¯ *2022-06-09*

##### ğŸ‰ arXiv Paper

- [NeurIPS_2022_åœ¨æŠ• Towards Understanding Why Mask-Reconstruction Pretraining Helps in Downstream Tasks](https://arxiv.org/pdf/2206.03826.pdf)

##### ğŸ‰ å·¥ä½œå†…å®¹ä¸è¿›å±•

- é†‰äº†ï¼Œæ·±åº¦ä¼°è®¡å·¥ä½œä»·å€¼ä¸é«˜ï¼Œè¯­ä¹‰ç›¸å…³æ€§å˜›ï¼Œè¿˜åœ¨åŠªåŠ›æ¢ç´¢ã€‚

##### ğŸ‰ è®¡åˆ’ä¸å®‰æ’

- äº†è§£ä¸€äº›è¯­ä¹‰ç›¸å…³æ€§ç‰¹åˆ«æ˜¯å¼±ç›‘ç£è¯­ä¹‰ç›¸å…³æ€§çš„å·¥ä½œ

- [CVPR_2018 End-to-end weakly-supervised semantic alignment](https://arxiv.org/pdf/1712.06861.pdf)
- [ECCV_2020 DHPF: Learning to Compose Hypercolumns for Visual Correspondence](https://arxiv.org/pdf/2007.10587.pdf)
- [ICCV_2021 DISCOBOX: Weakly Supervised Instance Segmentation and Semantic Correspondence from Box Supervision](https://openaccess.thecvf.com/content/ICCV2021/papers/Lan_DiscoBox_Weakly_Supervised_Instance_Segmentation_and_Semantic_Correspondence_From_Box_ICCV_2021_paper.pdf)

---

ğŸ¯ *2022-06-14*

##### ğŸ‰ arXiv Paper

- [NeurIPS_2022åœ¨æŠ•Discovering Object Masks with Transformers for Unsupervised Semantic Segmentation](https://arxiv.org/pdf/2206.06363.pdf)
- [NeurIPS_2022åœ¨æŠ•EnergyMatch: Energy-based Pseudo-Labeling for Semi-Supervised Learning](https://arxiv.org/pdf/2206.06359.pdf)
- [ICML_2022_Learning Domain Adaptive Object Detection with Probabilistic Teacher](https://arxiv.org/pdf/2206.06293.pdf)
- [NeurIPS_2022åœ¨æŠ•_Featurized Query R-CNN](https://arxiv.org/pdf/2206.06258.pdf)
- [NeurIPS_2022åœ¨æŠ•_Better Teacher Better Student: Dynamic Prior Knowledge for Knowledge Distillation](https://arxiv.org/pdf/2206.06067.pdf)
- [NeurIPS_2022åœ¨æŠ•_GLIPv2: Unifying Localization and VL Understanding](https://arxiv.org/pdf/2206.05836.pdf)

##### ğŸ‰ å·¥ä½œå†…å®¹ä¸è¿›å±•

- æŠŠIJCAI posteråšä¸€ä¸‹ã€‚

---

ğŸ¯ *2022-06-16*

##### ğŸ‰ arXiv Paper

- [Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone](https://arxiv.org/pdf/2206.07643.pdf)
- [SP-ViT: Learning 2D Spatial Priors for Vision Transformers](https://arxiv.org/pdf/2206.07662.pdf)
- [Visual Parser: Representing Part-whole Hierarchies with Transformers](https://arxiv.org/pdf/2107.05790.pdf)
- [Masked Siamese ConvNets](https://arxiv.org/pdf/2206.07700.pdf)
- [Masked Frequency Modeling for Self-Supervised Visual Pre-Training](https://arxiv.org/pdf/2206.07706.pdf)
- [Grounded Language-Image Pre-training](https://arxiv.org/abs/2112.03857)

---
  
ğŸ¯ *2022-06-20*
##### ğŸ‰ arXiv Paper

- [NeurIPS2022_Under_Review Rectify ViT Shortcut Learning by Visual Saliency](https://arxiv.org/pdf/2206.08567.pdf)
- [ICML_2022_VLMixer: Unpaired Vision-Language Pre-training via Cross-Modal CutMix](https://arxiv.org/pdf/2206.08919.pdf)
- [ECCV_2022_åœ¨æŠ•_Learning Implicit Feature Alignment Function for Semantic Segmentation](https://arxiv.org/pdf/2206.08655.pdf)
- [ECCV_2022_åœ¨æŠ•_Cross-task Attention Mechanism for Dense Multi-task Learning](https://arxiv.org/pdf/2206.08927.pdf)
- [BatchFormer: Learning to Explore Sample Relationships for Robust Representation Learning](https://arxiv.org/pdf/2203.01522v2.pdf) [å¼€æºä»£ç ](https://github.com/zhihou7/BatchFormer)
- [BatchFormerV2:Exploring Sample Relationships for Dense Representation Learning](https://arxiv.org/pdf/2204.01254.pdf)