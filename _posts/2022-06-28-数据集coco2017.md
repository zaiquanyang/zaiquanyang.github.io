---
layout: post
title: ç›®æ ‡æ£€æµ‹æ•°æ®é›†-COCO2017
tags: æ•°æ®é›†
---

## ğŸ‰ COCO2017æ•°æ®é›†ç®€ä»‹ä¸ä½¿ç”¨
---
MSCOCO æ•°æ®é›†æ˜¯å¾®è½¯æ„å»ºçš„ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶åŒ…å« detection, segmentation, keypointsç­‰ä»»åŠ¡, æ˜¯ç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸­ä¸»æµçš„æ•°æ®é›†ä¹‹ä¸€ã€‚

ä¸PASCAL COCOæ•°æ®é›†ç›¸æ¯”ï¼ŒCOCOä¸­çš„å›¾ç‰‡åŒ…å«äº†è‡ªç„¶å›¾ç‰‡ä»¥åŠç”Ÿæ´»ä¸­å¸¸è§çš„ç›®æ ‡å›¾ç‰‡ï¼ŒèƒŒæ™¯æ¯”è¾ƒå¤æ‚ï¼Œ**ç›®æ ‡æ•°é‡æ¯”è¾ƒå¤š**ï¼Œ**ç›®æ ‡å°ºå¯¸æ›´å°**ï¼Œå› æ­¤COCOæ•°æ®é›†ä¸Šçš„ä»»åŠ¡ä¹Ÿæ›´éš¾ï¼Œå½“å‰è¯„ä»·ä¸€ä¸ªæ£€æµ‹æ¨¡å‹å¥½åä¸€èˆ¬ä½¿ç”¨COCOæ•°æ®é›†ã€‚




### ğŸ‰ğŸ‰ æ•°æ®é›†ä¸‹è½½
---

[COCOæ•°æ®é›†è®ºæ–‡](https://arxiv.org/pdf/1405.0312.pdf)

[â¡ï¸cocoæ•°æ®é›†å®˜ç½‘](https://cocodataset.org/#download)

[ğŸ”„è®­ç»ƒé›†ä¸‹è½½é“¾æ¥ 118k/18GB](http://images.cocodataset.org/zips/train2017.zip)

[ğŸ”„éªŒè¯é›†ä¸‹è½½é“¾æ¥ 5k/1GB](http://images.cocodataset.org/zips/val2017.zip )

[ğŸ”„æµ‹è¯•é›†ä¸‹è½½é“¾æ¥ 41K/6GB](http://images.cocodataset.org/zips/test2017.zip )

[ğŸ”„æ•°æ®é›†stuffæ ‡æ³¨ä¸‹è½½é“¾æ¥](http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip)

ä»€ä¹ˆæ˜¯stuffç±»åˆ« â“
- ç®€å•çš„ç†è§£å°±æ˜¯stuffä¸­åŒ…å«æ²¡æœ‰æ˜ç¡®è¾¹ç•Œçš„ææ–™å’Œå¯¹è±¡.


### ğŸ‰ğŸ‰ æ•°æ®é›†ç±»åˆ«ä¿¡æ¯ä¸æ ‡æ³¨æ–‡ä»¶æ ¼å¼
---
#### ğŸ‰ğŸ‰ğŸ‰ ç±»åˆ«ä¿¡æ¯

**éœ€è¦å¼ºè°ƒçš„COCOç›®æ ‡æ£€æµ‹æ•°æ®é›†æ˜¯80ä¸ªç±»åˆ«ï¼Œä½†æ˜¯ç±»åˆ«IDæœ€å¤§æ˜¾ç¤ºä¸º90ï¼Œæœ€å°ä¸º1, ä¸åŒ…æ‹¬Background.**

objectçš„80ç±»ä¸stuffä¸­çš„91ç±»çš„åŒºåˆ«åœ¨å“ª â“
- ç®€å•çš„ç†è§£å°±æ˜¯object80ç±»æ˜¯stuff91ç±»çš„å­é›†ã€‚å¯¹äºæˆ‘ä»¬è‡ªå·±ä½¿ç”¨ï¼Œå¦‚æœä»…ä»…æ˜¯åšç›®æ ‡æ£€æµ‹ï¼ŒåŸºæœ¬åªç”¨object80ç±»å³å¯ã€‚

æ¯ä¸ªç±»åˆ«å¯¹åº”çš„å®ä¾‹ä¸ªæ•°åˆ†å¸ƒå›¾å¦‚ä¸‹ï¼š

<img src="http://tva1.sinaimg.cn/large/007d2DYjly1h3ocnnmdb1j31dc0b67c5.jpg"/>

#### ğŸ‰ğŸ‰ğŸ‰ æ ‡æ³¨æ–‡ä»¶æ ¼å¼

ä»¥ `instances_train2017`æ ‡æ³¨æ–‡ä»¶ä¸ºä¾‹ï¼š

```python
import json

annotation_file = '/data/code/Det_Code/COCO_2017/annotations/instances_train2017.json'
with open(annotation_file, 'r') as f:
    dataset = json.load(f)
```

è¯»å–å, å¾—åˆ°ä¸€ä¸ªåŒ…å«å››ä¸ªkey: ['info', 'licenses', 'images', 'annotations', 'categories']çš„å­—å…¸ã€‚

**annotations**

æ˜¯ä¸€ä¸ªåˆ—è¡¨å¯¹åº”å…¨éƒ¨å®ä¾‹è€Œä¸æ˜¯å›¾åƒçš„æ ‡æ³¨ä¿¡æ¯ï¼Œä»¥ç¬¬ä¸€ä¸ªå›¾åƒå®ä¾‹ä¸ºä¾‹æ¥è¯´ï¼š

```markdown
{'segmentation': [[239.97, 260.24, 222.04, 270.49, 199.84, 253.41, 213.5, 227.79, 259.62, 200.46, 274.13, 202.17, 277.55, 210.71, 249.37, 253.41, 237.41, 264.51, 242.54, 261.95, 228.87, 271.34]], 'area': 2765.1486500000005, 'iscrowd': 0, 'image_id': 558840, 'bbox': [199.84, 200.46, 77.71, 70.88], 'category_id': 58, 'id': 156}
```

æ¯ä¸ªkeyåˆ†åˆ«å¯¹åº”ï¼šç›®æ ‡çš„åˆ†å‰²ä¿¡æ¯ï¼ˆpolygonså¤šè¾¹å½¢ï¼‰ï¼ˆsegmentationï¼‰ï¼Œå®ä¾‹é¢ç§¯ï¼ˆareaï¼‰ï¼Œç›®æ ‡è¾¹ç•Œæ¡†ä¿¡æ¯ï¼ˆå·¦ä¸Šè§’x,yåæ ‡ï¼Œä»¥åŠå®½é«˜ï¼‰ï¼ˆbboxï¼‰ï¼Œç±»åˆ«idï¼ˆcategory_idï¼‰ã€‚

**categories**

æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ˆå…ƒç´ ä¸ªæ•°å¯¹åº”æ£€æµ‹ç›®æ ‡çš„ç±»åˆ«æ•°ï¼‰åˆ—è¡¨ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªdictå¯¹åº”ä¸€ä¸ªç±»åˆ«çš„ç›®æ ‡ä¿¡æ¯ï¼ŒåŒ…æ‹¬ç±»åˆ«idã€ç±»åˆ«åç§°å’Œæ‰€å±è¶…ç±»ï¼Œæ³¨æ„å®é™…åªæœ‰80ä¸ªObjectç±»ã€‚å¦‚æœ€åä¸€ä¸ªç±»åˆ«ï¼š

```markdown
79 {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}
```

**images**

æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ˆå…ƒç´ ä¸ªæ•°å¯¹åº”å›¾åƒçš„å¼ æ•°ï¼‰ï¼Œåˆ—è¡¨ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªdictï¼Œå¯¹åº”ä¸€å¼ å›¾ç‰‡çš„ç›¸å…³ä¿¡æ¯ã€‚åŒ…æ‹¬å¯¹åº”å›¾åƒåç§°ã€å›¾åƒå®½åº¦ã€é«˜åº¦ç­‰ä¿¡æ¯ã€‚
```markdown
{'license': 3, 'file_name': '000000391895.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000391895.jpg', 'height': 360, 'width': 640, 'date_captured': '2013-11-14 11:18:45', 'flickr_url': 'http://farm9.staticflickr.com/8186/8119368305_4e622c8349_z.jpg', 'id': 391895}
```
æ¯ä¸ªkeyåˆ†åˆ«å¯¹åº”ï¼Œæ–‡ä»¶å/file_nameï¼Œé«˜åº¦/heightï¼Œå®½åº¦/width


#### ğŸ‰ğŸ‰ğŸ‰  å®˜æ–¹cocoAPIæŸ¥çœ‹æ•°æ®
å®˜æ–¹æœ‰ç»™å‡ºä¸€ä¸ªè¯»å–MS COCOæ•°æ®é›†ä¿¡æ¯çš„API, è¿™ä¸ªAPIå…·æœ‰æ•°æ®çš„è¯»å–ç­‰é‡è¦åŠŸèƒ½ã€‚
```shell
pip install pycocotools  
```
**ä½¿ç”¨`pycocotools` å¯è§†åŒ–å®ä¾‹è¾¹ç•Œæ¡†**

```python
import os
from pycocotools.coco import COCO
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt

json_path = "/data/code/Det_Code/COCO_2017/annotations/instances_val2017.json"  # å›¾åƒæ³¨é‡Šæ–‡ä»¶è·¯å¾„
img_path = "/data/code/Det_Code/COCO_2017/val2017"   # å›¾åƒæ–‡ä»¶è·¯å¾„

# COCOæ˜¯ å®˜æ–¹APIä¸­åŠ è½½æ³¨é‡Šæ–‡ä»¶çš„ ç±»
coco = COCO(annotation_file=json_path)

# è·å–æ³¨é‡Šæ–‡ä»¶ä¸­çš„imageså…¨éƒ¨ç›¸å…³ä¿¡æ¯
ids = list(sorted(coco.imgs.keys()))
print("number of images: {}".format(len(ids)))

# get all coco class labels
coco_classes = dict([(v["id"], v["name"]) for k, v in coco.cats.items()])

# éå†å‰ä¸¤å¼ å›¾åƒ
for img_id in ids[:2]:
    # è·å–å¯¹åº”å›¾åƒidçš„æ‰€æœ‰annotations idxä¿¡æ¯
    ann_ids = coco.getAnnIds(imgIds=img_id)

    # æ ¹æ®annotations idxä¿¡æ¯è·å–æ‰€æœ‰æ ‡æ³¨ä¿¡æ¯
    targets = coco.loadAnns(ann_ids)

    # get image file name
    path = coco.loadImgs(img_id)[0]['file_name']

    # read image
    img = Image.open(os.path.join(img_path, path)).convert('RGB')
    draw = ImageDraw.Draw(img)
    # draw box to image
    for target in targets:
        x, y, w, h = target["bbox"]
        x1, y1, x2, y2 = x, y, int(x + w), int(y + h)
        draw.rectangle((x1, y1, x2, y2))
        draw.text((x1, y1), coco_classes[target["category_id"]])

    # show image
    plt.imshow(img)
    plt.savefig('example_{}.png'.format(img_id), dpi=50)
    plt.show()
```

<div align=center><img src="http://tva1.sinaimg.cn/large/007d2DYjly1h3of4pm0a8j30p00gotjy.jpg" width="488"></div>
<div align=center><img src="http://tva1.sinaimg.cn/large/007d2DYjly1h3of5r1nanj30p00go13a.jpg" width="488"></div>


è¿™é‡Œéœ€è¦å‚è€ƒ[csdnåšå®¢](https://blog.csdn.net/qq_37541097/article/details/113247318)ç»™å‡ºçš„ä»£ç ï¼Œé‡Œé¢è°ƒç”¨äº†APIä¸­çš„ä¸å°‘å‡½æ•°ï¼Œè¿˜éœ€è¦è¿›ä¸€æ­¥å­¦ä¹ ã€‚


**ä½¿ç”¨`pycocotools` å¯è§†åŒ–å®ä¾‹åˆ†å‰²mask**

è¿™é‡Œä¾æ—§å¯ä»¥å‚è€ƒ[csdnåšå®¢](https://blog.csdn.net/qq_37541097/article/details/113247318)ï¼Œè¿™é‡Œå°±ä¸æ”¾äº†ã€‚

---

### ğŸ‰ğŸ‰ è¯„ä¼°æ ‡å‡†

**mAP**

PASCAL ä¸­åœ¨æµ‹è¯•mAPæ—¶ï¼Œæ˜¯åœ¨IOU=0.5æ—¶æµ‹çš„ï¼Œè€ŒCOCOçš„ä¸»è¦è¯„ä»·æŒ‡æ ‡æ˜¯APï¼ŒæŒ‡ IOUä»0.5åˆ°0.95 æ¯å˜åŒ– 0.05 å°±æµ‹è¯•ä¸€æ¬¡ APï¼Œç„¶åæ±‚è¿™10æ¬¡æµ‹é‡ç»“æœçš„å¹³å‡å€¼ä½œä¸ºæœ€ç»ˆçš„ APï¼Œä¹Ÿå°±æ˜¯è¯´COCOè¯„ä»·æŒ‡æ ‡çš„ AP@0.5 è·ŸPASCAL VOCä¸­çš„mAPæ˜¯ç›¸åŒçš„å«ä¹‰ï¼ŒAP@0.75 è·ŸPASCAL VOCä¸­çš„mAPä¹Ÿç›¸åŒï¼Œåªæ˜¯IOUé˜ˆå€¼æé«˜åˆ°äº†0.75ï¼Œæ˜¾ç„¶è¿™ä¸ªè¦æ±‚çš„å‡†ç¡®åº¦æ›´é«˜ï¼Œç²¾åº¦ä¹Ÿä¼šæ›´ä½ã€‚

IOUè¶Šé«˜ï¼ŒAPå°±è¶Šä½ï¼Œæ‰€ä»¥æœ€ç»ˆçš„å¹³å‡ä¹‹åçš„APè¦æ¯” AP@0.5 å°å¾ˆå¤šï¼Œè¿™ä¹Ÿå°±æ˜¯ä¸ºä»€ä¹ˆCOCOçš„AP è¶…è¿‡ 50%çš„åªæœ‰å¯¥å¯¥å‡ ä¸ªè€Œå·²ï¼Œå› ä¸ºè¶…è¿‡50%è¿˜æ˜¯å¾ˆéš¾çš„ã€‚

**é’ˆå¯¹ä¸åŒå¤§å°å›¾ç‰‡çš„è¯„æµ‹**

COCOæ•°æ®é›†è¿˜é’ˆå¯¹ ä¸‰ç§ä¸åŒå¤§å°ï¼ˆsmallï¼Œmediumï¼Œlargeï¼‰ çš„å›¾ç‰‡æå‡ºäº†æµ‹é‡æ ‡å‡†ï¼ŒCOCOä¸­åŒ…å«å¤§çº¦ 41% çš„å°ç›®æ ‡ (area<32Ã—32), 34% çš„ä¸­ç­‰ç›®æ ‡ (32Ã—32<area<96Ã—96), å’Œ 24% çš„å¤§ç›®æ ‡ (area>96Ã—96). å°ç›®æ ‡çš„APæ˜¯å¾ˆéš¾æå‡çš„ã€‚

**pycocotools**åŒæ ·ç»™å‡ºä¸Šè¿°è¯„ä»·æ¨¡å‹çš„ä»£ç ã€‚


### ğŸ‰ğŸ‰ COCOæ•°æ®é›†çš„è¯»å–

#### ğŸ‰ğŸ‰ğŸ‰ COCOç›®æ ‡æ£€æµ‹æ•°æ®é›†ç±»å®ç°

è¿™é‡Œä»¥DETRä¸­è¯»å–ä»£ç å®ç°ä¸ºä¾‹ï¼ŒCOCOç›®æ ‡æ£€æµ‹æ•°æ®é›†ç±» `CocoDetection` å®šä¹‰ä¸ºï¼š

```python

class CocoDetection(torchvision.datasets.CocoDetection):
    def __init__(self, img_folder, ann_file, transforms, return_masks):
        super(CocoDetection, self).__init__(img_folder, ann_file)
        self._transforms = transforms
        self.prepare = ConvertCocoPolysToMask(return_masks)

    def __getitem__(self, idx):
        # breakpoint()
        # img: PIL.Image è¯»å–çš„ç»“æœï¼Œ target æ˜¯è¿™ä¸ªå›¾åƒçš„å…¨éƒ¨å®ä¾‹æ ‡æ³¨ä¿¡æ¯
        img, target = super(CocoDetection, self).__getitem__(idx)  
        image_id = self.ids[idx]
        target = {'image_id': image_id, 'annotations': target}
        img, target = self.prepare(img, target)
        # å¯¹targetè¿›ä¸€æ­¥å¤„ç†ï¼Œä½¿å…¶æ–¹ä¾¿åé¢çš„è®­ç»ƒ
        if self._transforms is not None:
            img, target = self._transforms(img, target)
        return img, target
```
å¯ä»¥çœ‹åˆ°è¿™ä¸ªç±»ç»§æ‰¿äº†è¾ƒå¤š`torchvision.datasets.CocoDetection`çš„æ–¹æ³•ï¼Œ`torchvision.datasets.CocoDetection`æ˜¯`torchvision`å€ŸåŠ© cocoAPIä¹Ÿå°±æ˜¯ pycocotools åŒ…è£…å®ç°çš„ï¼Œé‡Œé¢åŒ…å«äº†è¾ƒå¤šè¯¸å¦‚å›¾åƒè¯»å–ï¼Œæ³¨é‡Šè¯»å–çš„å‡½æ•°ã€‚è¿™é‡Œæš‚ä¸åšä»”ç»†æ·±ç©¶ï¼Œåªç»™å‡ºæˆ‘ä»¬åœ¨ä½¿ç”¨æ—¶æ¶‰åŠå¾—åˆ°çš„ `CocoDetection`ç±»çš„è¾“å…¥å’Œè¾“å‡ºã€‚
 
`CocoDetection`çš„åˆå§‹åŒ–åªç”¨ç»™å‡ºå‡†å¤‡å¥½äº†çš„COCO2017æ•°æ®é›†çš„å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„ **img_folder**ï¼Œ æ¯”å¦‚è®­ç»ƒé›†å›¾åƒæ•°æ®`/data/code/Det_Code/COCO_2017/train2017`,  ä»¥åŠæ³¨é‡Šæ–‡ä»¶è·¯å¾„ **ann_file**ï¼Œå¦‚`/data/code/Det_Code/COCO_2017/annotations/instances_train2017.json`ï¼š **transforms**ï¼ˆæŒ‡å›¾åƒçš„å¢å¹¿å˜æ¢å‡½æ•°ï¼‰ï¼Œ**return_masks**ï¼ˆå¯¹äºæ£€æµ‹æ¶‰åŠä¸åˆ°, ä¸åˆ†å‰²ç›¸å…³ï¼‰ã€‚

#### ğŸ‰ğŸ‰ğŸ‰ ConvertCocoPolysToMaskçš„å®ç°

DETRç»™å‡ºçš„å®ç°å¦‚ä¸‹ï¼š

```python
def convert_coco_poly_to_mask(segmentations, height, width):
    masks = []
    for polygons in segmentations:
        rles = coco_mask.frPyObjects(polygons, height, width)
        mask = coco_mask.decode(rles)
        if len(mask.shape) < 3:
            mask = mask[..., None]
        mask = torch.as_tensor(mask, dtype=torch.uint8)
        mask = mask.any(dim=2)
        masks.append(mask)
    if masks:
        masks = torch.stack(masks, dim=0)
    else:
        masks = torch.zeros((0, height, width), dtype=torch.uint8)
    return masks


class ConvertCocoPolysToMask(object):
    def __init__(self, return_masks=False):
        self.return_masks = return_masks

    def __call__(self, image, target):
        w, h = image.size

        image_id = target["image_id"]
        image_id = torch.tensor([image_id])

        anno = target["annotations"]

        anno = [obj for obj in anno if 'iscrowd' not in obj or obj['iscrowd'] == 0]

        boxes = [obj["bbox"] for obj in anno]
        # guard against no boxes via resizing
        boxes = torch.as_tensor(boxes, dtype=torch.float32).reshape(-1, 4)
        boxes[:, 2:] += boxes[:, :2]
        boxes[:, 0::2].clamp_(min=0, max=w)
        boxes[:, 1::2].clamp_(min=0, max=h)

        classes = [obj["category_id"] for obj in anno]
        classes = torch.tensor(classes, dtype=torch.int64)

        if self.return_masks:
            segmentations = [obj["segmentation"] for obj in anno]
            masks = convert_coco_poly_to_mask(segmentations, h, w)

        keypoints = None
        if anno and "keypoints" in anno[0]:
            keypoints = [obj["keypoints"] for obj in anno]
            keypoints = torch.as_tensor(keypoints, dtype=torch.float32)
            num_keypoints = keypoints.shape[0]
            if num_keypoints:
                keypoints = keypoints.view(num_keypoints, -1, 3)

        keep = (boxes[:, 3] > boxes[:, 1]) & (boxes[:, 2] > boxes[:, 0])
        boxes = boxes[keep]
        classes = classes[keep]
        if self.return_masks:
            masks = masks[keep]
        if keypoints is not None:
            keypoints = keypoints[keep]

        target = {}
        target["boxes"] = boxes
        target["labels"] = classes
        if self.return_masks:
            target["masks"] = masks
        target["image_id"] = image_id
        if keypoints is not None:
            target["keypoints"] = keypoints

        # for conversion to coco api
        area = torch.tensor([obj["area"] for obj in anno])
        iscrowd = torch.tensor([obj["iscrowd"] if "iscrowd" in obj else 0 for obj in anno])
        target["area"] = area[keep]
        target["iscrowd"] = iscrowd[keep]

        target["orig_size"] = torch.as_tensor([int(h), int(w)])
        target["size"] = torch.as_tensor([int(h), int(w)])

        return image, target
```
çœ‹ç€è¿˜æŒºå¤æ‚å•Šï¼Œè¿™é‡Œæˆ‘ä»¬åŒæ ·åªç»™å‡ºå‡½æ•°çš„ä½œç”¨ã€‚
å¤„ç†å‰ä¸å¤„ç†åçš„imageæ²¡å‘ç”Ÿå˜åŒ–ï¼Œå‘ç”Ÿå˜åŒ–çš„æ˜¯target.
å¤„ç†å‰çš„æ ·å­å¦‚ä¸‹ï¼Œä¸€å…±åŒ…å«äº†8ä¸ªå®ä¾‹çš„æ ‡æ³¨ä¿¡æ¯

```markdown
[
    {'segmentation': [[500.49, 473.53, 599.73, 419.6, 612.67, 375.37, 608.36, 354.88, 528.54, 269.66, 457.35, 201.71, 420.67, 187.69, 389.39, 192.0, 19.42, 360.27, 1.08, 389.39, 2.16, 427.15, 20.49, 473.53]], 'area': 120057.13925, 'iscrowd': 0, 'image_id': 9, 'bbox': [1.08, 187.69, 611.59, 285.84], 'category_id': 51, 'id': 1038967}, <br>
    {'segmentation': [[357.03, 69.03, 311.73, 15.1, 550.11, 4.31, 631.01, 62.56, 629.93, 88.45, 595.42, 185.53, 513.44, 230.83, 488.63, 232.99, 437.93, 190.92, 429.3, 189.84, 434.7, 148.85, 410.97, 121.89, 359.19, 74.43, 358.11, 65.8]], 'area': 44434.751099999994, 'iscrowd': 0, 'image_id': 9, 'bbox': [311.73, 4.31, 319.28, 228.68], 'category_id': 51, 'id': 1039564}, 
    {'segmentation': [[249.6, 348.99, 267.67, 311.72, 291.39, 294.78, 304.94, 294.78, 326.4, 283.48, 345.6, 273.32, 368.19, 269.93, 385.13, 268.8, 388.52, 257.51, 393.04, 250.73, 407.72, 240.56, 425.79, 230.4, 441.6, 229.27, 447.25, 237.18, 447.25, 256.38, 456.28, 254.12, 475.48, 263.15, 486.78, 271.06, 495.81, 264.28, 498.07, 257.51, 500.33, 255.25, 507.11, 259.76, 513.88, 266.54, 513.88, 273.32, 513.88, 276.71, 526.31, 276.71, 526.31, 286.87, 519.53, 291.39, 519.53, 297.04, 524.05, 306.07, 525.18, 315.11, 529.69, 329.79, 529.69, 337.69, 530.82, 348.99, 536.47, 339.95, 545.51, 350.12, 555.67, 360.28, 557.93, 380.61, 561.32, 394.16, 565.84, 413.36, 522.92, 441.6, 469.84, 468.71, 455.15, 474.35, 307.2, 474.35, 316.24, 464.19, 330.92, 438.21, 325.27, 399.81, 310.59, 378.35, 301.55, 371.58, 252.99, 350.12]], 'area': 49577.94434999999, 'iscrowd': 0, 'image_id': 9, 'bbox': [249.6, 229.27, 316.24, 245.08], 'category_id': 56, 'id': 1058555}, 
    {'segmentation': [[434.48, 152.33, 433.51, 184.93, 425.44, 189.45, 376.7, 195.58, 266.94, 248.53, 179.78, 290.17, 51.62, 346.66, 16.43, 366.68, 1.9, 388.63, 0.0, 377.33, 0.0, 357.64, 0.0, 294.04, 22.56, 294.37, 56.14, 300.82, 83.58, 300.82, 109.08, 289.2, 175.26, 263.38, 216.9, 243.36, 326.34, 197.52, 387.03, 172.34, 381.54, 162.33, 380.89, 147.16, 380.89, 140.06, 370.89, 102.29, 330.86, 61.94, 318.91, 48.38, 298.57, 47.41, 287.28, 37.73, 259.51, 33.85, 240.14, 32.56, 240.14, 28.36, 247.57, 24.17, 271.46, 15.13, 282.11, 13.51, 296.96, 18.68, 336.34, 55.48, 391.55, 106.81, 432.87, 147.16], [62.46, 97.21, 130.25, 69.77, 161.25, 59.12, 183.52, 52.02, 180.94, 59.12, 170.93, 78.17, 170.28, 90.76, 157.05, 95.92, 130.25, 120.78, 119.92, 129.49, 102.17, 115.29, 64.72, 119.81, 0.0, 137.89, 0.0, 120.13, 0.0, 117.87]], 'area': 24292.781700000007, 'iscrowd': 0, 'image_id': 9, 'bbox': [0.0, 13.51, 434.48, 375.12], 'category_id': 51, 'id': 1534147}, 
    {'segmentation': [[376.2, 61.55, 391.86, 46.35, 424.57, 40.36, 441.62, 43.59, 448.07, 50.04, 451.75, 63.86, 448.07, 68.93, 439.31, 70.31, 425.49, 73.53, 412.59, 75.38, 402.92, 84.13, 387.71, 86.89, 380.8, 70.77]], 'area': 2239.2924, 'iscrowd': 0, 'image_id': 9, 'bbox': [376.2, 40.36, 75.55, 46.53], 'category_id': 55, 'id': 1913551}, 
    {'segmentation': [[473.92, 85.64, 469.58, 83.47, 465.78, 78.04, 466.87, 72.08, 472.84, 59.59, 478.26, 47.11, 496.71, 38.97, 514.62, 40.6, 521.13, 49.28, 523.85, 55.25, 520.05, 63.94, 501.06, 72.62, 482.6, 82.93]], 'area': 1658.8913000000007, 'iscrowd': 0, 'image_id': 9, 'bbox': [465.78, 38.97, 58.07, 46.67], 'category_id': 55, 'id': 1913746}, 
    {'segmentation': [[385.7, 85.85, 407.12, 80.58, 419.31, 79.26, 426.56, 77.94, 435.45, 74.65, 442.7, 73.66, 449.95, 73.99, 456.87, 77.94, 463.46, 83.87, 467.74, 92.77, 469.39, 104.63, 469.72, 117.15, 469.39, 135.27, 468.73, 141.86, 466.09, 144.17, 449.29, 141.53, 437.1, 136.92, 430.18, 129.67]], 'area': 3609.3030499999995, 'iscrowd': 0, 'image_id': 9, 'bbox': [385.7, 73.66, 84.02, 70.51], 'category_id': 55, 'id': 1913856}, 
    {'segmentation': [[458.81, 24.94, 437.61, 4.99, 391.48, 2.49, 364.05, 56.1, 377.77, 73.56, 377.77, 56.1, 392.73, 41.14, 403.95, 41.14, 420.16, 39.9, 435.12, 42.39, 442.6, 46.13, 455.06, 31.17]], 'area': 2975.276, 'iscrowd': 0, 'image_id': 9, 'bbox': [364.05, 2.49, 94.76, 71.07], 'category_id': 55, 'id': 1914001}]
```

å¤„ç†åçš„ç»“æœæ˜¯ï¼š
```markdown
{
    'boxes': 
        tensor([[  1.0800, 187.6900, 612.6700, 473.5300],
                [311.7300,   4.3100, 631.0100, 232.9900],
                [249.6000, 229.2700, 565.8400, 474.3500],
                [  0.0000,  13.5100, 434.4800, 388.6300],
                [376.2000,  40.3600, 451.7500,  86.8900],
                [465.7800,  38.9700, 523.8500,  85.6400],
                [385.7000,  73.6600, 469.7200, 144.1700],
                [364.0500,   2.4900, 458.8100,  73.5600]]), 
    'labels': 
        tensor([51, 51, 56, 51, 55, 55, 55, 55]), 
    'image_id': tensor([9]), 
    'area': 
        tensor([120057.1406,  44434.7500,  49577.9453,  24292.7812,   2239.2925, 1658.8914,   3609.3030,   2975.2759]), 
    'iscrowd': 
        tensor([0, 0, 0, 0, 0, 0, 0, 0]), 
    'orig_size':  tensor([480, 640]), 
    'size': tensor([480, 640])}
```
è‡³æ­¤å°±å¤§æ¦‚æ¸…æ¥šäº†COCOæ•°æ®é›†çš„ç®€å•ä½¿ç”¨äº†ã€‚


### ğŸ‰ğŸ‰ å‚è€ƒ
---

[MS COCOæ•°æ®é›†ä»‹ç»ä»¥åŠpycocotoolsç®€å•ä½¿ç”¨](https://blog.csdn.net/qq_37541097/article/details/113247318)

[ç›®æ ‡æ£€æµ‹æ•°æ®é›†MSCOCOç®€ä»‹](https://arleyzhang.github.io/articles/e5b86f16/)