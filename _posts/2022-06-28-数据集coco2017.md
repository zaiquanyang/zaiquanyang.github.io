---
layout: post
title: 目标检测数据集-COCO2017
tags: 数据集
---

## 🍉 COCO2017数据集简介

MSCOCO 数据集是微软构建的一个数据集，其包含 detection, segmentation, keypoints等任务, 是目标检测数据集中主流的数据集之一。

与PASCAL COCO数据集相比，COCO中的图片包含了自然图片以及生活中常见的目标图片，背景比较复杂，**目标数量比较多**，**目标尺寸更小**，因此COCO数据集上的任务也更难，当前评价一个检测模型好坏一般使用COCO数据集。

---


### 🍉 数据集下载

[COCO数据集论文](https://arxiv.org/pdf/1405.0312.pdf)

[➡️coco数据集官网](https://cocodataset.org/#download)

[🔄训练集下载链接 118k/18GB](http://images.cocodataset.org/zips/train2017.zip)

[🔄验证集下载链接 5k/1GB](http://images.cocodataset.org/zips/val2017.zip )

[🔄测试集下载链接 41K/6GB](http://images.cocodataset.org/zips/test2017.zip )

[🔄数据集stuff标注下载链接](http://images.cocodataset.org/annotations/stuff_annotations_trainval2017.zip)

什么是stuff类别 ❓
- 简单的理解就是stuff中包含没有明确边界的材料和对象.

---
### 🍉 数据集类别信息与标注文件格式

#### 🍉类别信息

**需要强调的COCO目标检测数据集是80个类别，但是类别ID最大显示为90，最小为1, 不包括Background.**

object的80类与stuff中的91类的区别在哪 ❓
- 简单的理解就是object80类是stuff91类的子集。对于我们自己使用，如果仅仅是做目标检测，基本只用object80类即可。

每个类别对应的实例个数分布图如下：

<img src="http://tva1.sinaimg.cn/large/007d2DYjly1h3ocnnmdb1j31dc0b67c5.jpg"/>

#### 🍉 标注文件格式

以 `instances_train2017`标注文件为例：

```python
import json

annotation_file = '/data/code/Det_Code/COCO_2017/annotations/instances_train2017.json'
with open(annotation_file, 'r') as f:
    dataset = json.load(f)
```

读取后, 得到一个包含四个key: ['info', 'licenses', 'images', 'annotations', 'categories']的字典。

**annotations**：是一个列表对应全部实例而不是图像的标注信息，以第一个图像实例为例来说：

```markdown
{'segmentation': [[239.97, 260.24, 222.04, 270.49, 199.84, 253.41, 213.5, 227.79, 259.62, 200.46, 274.13, 202.17, 277.55, 210.71, 249.37, 253.41, 237.41, 264.51, 242.54, 261.95, 228.87, 271.34]], 'area': 2765.1486500000005, 'iscrowd': 0, 'image_id': 558840, 'bbox': [199.84, 200.46, 77.71, 70.88], 'category_id': 58, 'id': 156}
```

每个key分别对应：目标的分割信息（polygons多边形）（segmentation），实例面积（area），目标边界框信息（左上角x,y坐标，以及宽高）（bbox），类别id（category_id）。

**categories**：是一个列表（元素个数对应检测目标的类别数）列表中每个元素都是一个dict对应一个类别的目标信息，包括类别id、类别名称和所属超类，注意实际只有80个Object类。

**images**：是一个列表（元素个数对应图像的张数），列表中每个元素都是一个dict，对应一张图片的相关信息。包括对应图像名称、图像宽度、高度等信息。
```markdown
{'license': 3, 'file_name': '000000391895.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000391895.jpg', 'height': 360, 'width': 640, 'date_captured': '2013-11-14 11:18:45', 'flickr_url': 'http://farm9.staticflickr.com/8186/8119368305_4e622c8349_z.jpg', 'id': 391895}
```
每个key分别对应，文件名/file_name，高度/height，宽度/width

---

#### 🍉  官方cocoAPI查看数据
官方有给出一个读取MS COCO数据集信息的API, 这个API具有数据的读取等重要功能。
```shell
pip install pycocotools  
```
**使用`pycocotools` 可视化实例边界框**

```python
import os
from pycocotools.coco import COCO
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt

json_path = "/data/code/Det_Code/COCO_2017/annotations/instances_val2017.json"  # 图像注释文件路径
img_path = "/data/code/Det_Code/COCO_2017/val2017"   # 图像文件路径

# COCO是 官方API中加载注释文件的 类
coco = COCO(annotation_file=json_path)

# 获取注释文件中的images全部相关信息
ids = list(sorted(coco.imgs.keys()))
print("number of images: {}".format(len(ids)))

# get all coco class labels
coco_classes = dict([(v["id"], v["name"]) for k, v in coco.cats.items()])

# 遍历前两张图像
for img_id in ids[:2]:
    # 获取对应图像id的所有annotations idx信息
    ann_ids = coco.getAnnIds(imgIds=img_id)

    # 根据annotations idx信息获取所有标注信息
    targets = coco.loadAnns(ann_ids)

    # get image file name
    path = coco.loadImgs(img_id)[0]['file_name']

    # read image
    img = Image.open(os.path.join(img_path, path)).convert('RGB')
    draw = ImageDraw.Draw(img)
    # draw box to image
    for target in targets:
        x, y, w, h = target["bbox"]
        x1, y1, x2, y2 = x, y, int(x + w), int(y + h)
        draw.rectangle((x1, y1, x2, y2))
        draw.text((x1, y1), coco_classes[target["category_id"]])

    # show image
    plt.imshow(img)
    plt.savefig('example_{}.png'.format(img_id), dpi=50)
    plt.show()
```

<div align=center><img src="http://tva1.sinaimg.cn/large/007d2DYjly1h3of4pm0a8j30p00gotjy.jpg" width="488"></div>
<div align=center><img src="http://tva1.sinaimg.cn/large/007d2DYjly1h3of5r1nanj30p00go13a.jpg" width="488"></div>


这里需要参考[csdn博客](https://blog.csdn.net/qq_37541097/article/details/113247318)给出的代码，里面调用了API中的不少函数，还需要进一步学习。


**使用`pycocotools` 可视化实例分割mask**

这里依旧可以参考[csdn博客](https://blog.csdn.net/qq_37541097/article/details/113247318)，这里就不放了。

---

#### 🍉 评估标准

**mAP**

PASCAL 中在测试mAP时，是在IOU=0.5时测的，而COCO的主要评价指标是AP，指 IOU从0.5到0.95 每变化 0.05 就测试一次 AP，然后求这10次测量结果的平均值作为最终的 AP，也就是说COCO评价指标的 AP@0.5 跟PASCAL VOC中的mAP是相同的含义，AP@0.75 跟PASCAL VOC中的mAP也相同，只是IOU阈值提高到了0.75，显然这个要求的准确度更高，精度也会更低。

IOU越高，AP就越低，所以最终的平均之后的AP要比 AP@0.5 小很多，这也就是为什么COCO的AP 超过 50%的只有寥寥几个而已，因为超过50%还是很难的。

**针对不同大小图片的评测**

COCO数据集还针对 三种不同大小（small，medium，large） 的图片提出了测量标准，COCO中包含大约 41% 的小目标 (area<32×32), 34% 的中等目标 (32×32<area<96×96), 和 24% 的大目标 (area>96×96). 小目标的AP是很难提升的。

**pycocotools**同样给出上述评价模型的代码。

---

#### 🍉 参考

[MS COCO数据集介绍以及pycocotools简单使用](https://blog.csdn.net/qq_37541097/article/details/113247318)
[目标检测数据集MSCOCO简介](https://arleyzhang.github.io/articles/e5b86f16/)