---
# layout: post
title: Coarse-to-Fine Vision Transformer  BMVC-2022
tags: Transformer 
---

ä½œè€…æ˜¯å¦é—¨å¤§å­¦ Rongrong Ji å›¢é˜Ÿã€‚

[Coarse-to-Fine Vision Transformer](https://arxiv.org/abs/2203.03821)

[Codeå·²å¼€æº](https://github.com/ChenMnZ/CF-ViT)



### ğŸ¦– åŠ¨æœº


ä½œè€…åŠ¨æœºæ˜¯æƒ³è®¾è®¡ä¸€ä¸ªæ›´åŠ é«˜æ•ˆçš„ VIT, å›¾åƒå†—ä½™ä¿¡æ¯è¾ƒå¤šï¼Œ é€ æˆ VIT è¿‡äºæ˜‚è´µçš„è®¡ç®—é‡ï¼Œæå‡ºçš„
ä¸¤é˜¶æ®µ VIT åŒ…æ‹¬ coarse  inference  stage å’Œ fine-grained  granularity stageã€‚

åœ¨ç²—ç²’åº¦é˜¶æ®µï¼Œåˆ‡åˆ†çš„ Patch æ¯”è¾ƒå¤§ï¼Œåºåˆ—é•¿åº¦çŸ­ï¼Œå¯ä»¥è¿›è¡Œæ›´åŠ é«˜æ•ˆçš„å…¨å±€æ³¨æ„åŠ›è®¡ç®—ï¼Œè€Œå å¦‚æœåˆ†ç±»çš„ç½®ä¿¡åº¦ä¸é«˜ï¼Œå°±å†æ‰§è¡Œ fine-grained  granularity stageï¼Œ **the  informative  patches  are  identified  and  further  re-split  in  a  fine-grained  granularityã€‚**

å…¶å®ä¹‹å‰å·²ç»æœ‰ä¸å°‘è‡´åŠ›äºå‡å°‘VITä¸­ redundant tokensï¼Œåƒ

PS-VIT (tch slimmingfor  efficient  vision  transformers) , 

DynamicViT(Dynamicvit:  Efficientvision transformers with dynamic token sparsification), 

EVIT(Evit: Expediting visiontransformers via token reorganizations)ã€‚

DGE (ynamicgrained encoder for vision transformer)

DVT (Not all images are worth16x16 words: Dynamic transformers for efficient image recognition)

...

ä½œè€…æŒ‡å‡ºä¸¤ç‚¹è§‚å¯Ÿï¼š

- ç²—ç²’åº¦æ¯”å¦‚ 7x7 çš„ Patchåˆ’åˆ†ä¹Ÿèƒ½å¤ŸåŸºæœ¬è¯†åˆ«å‡ºå›¾åƒä¸­çš„ informative regionï¼Œå¦‚å³å›¾æ‰€ç¤ºï¼Œæ³¨æ„çš„æ˜¯è¿™é‡Œæ˜¯æ ¹æ® Cls-Token çš„ Attentionæ¥åˆ¤æ–­ä¸€ä¸ª Patch çš„é‡è¦æ€§ï¼Œè¿™åœ¨ä¹‹å‰çš„å·¥ä½œå·²ç»è¢«æå‡ºè¿‡ï¼Œå·¦å›¾æ˜¯æŠŠ 14x14=196ä¸ªPatchæŒ‰ç…§é‡è¦æ€§åˆ†æˆå‰100å’Œå100åˆ†åˆ«è¾“å…¥åˆ°è®­ç»ƒå¥½çš„ Deit-S ä¸­è®¡ç®—åˆ†ç±»å‡†ç¡®åº¦ï¼Œæ¨ªåæ ‡æ˜¯12ä¸ªindexï¼Œä¼°è®¡æ˜¯å¯¹åº”12ä¸ªBlockçš„ Cls-Attentionçš„ç»“æœã€‚

<div align=center><img src="http://tva1.sinaimg.cn/large/007d2DYjly1h2p4s9la4gj30yt0fqwr3.jpg" width="600"></div>

- å¤§å¤šæ•°çš„å›¾ç‰‡å…¶å®ä¸éœ€è¦ 14x14 è¿™ä¹ˆç»†çš„åˆ’åˆ†å°±èƒ½å–å¾—å¾ˆå¥½çš„åˆ†ç±»ç»“æœï¼Œå¥½å§å·®äº†6ä¸ªç‚¹ï¼Œä¹Ÿä¸ç®—å°‘äº†ã€‚

<div align=center><img src="http://tva1.sinaimg.cn/large/007d2DYjly1h2p58ayjl4j308v05uac7.jpg" width="200"></div>

å—ä¸Šé¢çš„è§‚å¯Ÿå¯å‘ï¼Œå°±æå‡ºäº† coarse-to-fine  vision  transformer.

### ğŸ¦– æ–¹æ³•


<div align=center><img src="http://tva1.sinaimg.cn/large/007d2DYjly1h2p4t3pkxbj30z30fjtfq.jpg" width="600"></div>

- **Coarse Inference Stage**
è¿™ä¸€æ­¥å’Œæ™®é€šçš„VITæ²¡ä»€ä¹ˆåŒºåˆ«å°±æ˜¯æœ‰ä¸€ä¸ª Informative Region Identificationï¼Œ è¯¥æ­¥æ˜¯è¯†åˆ«å‡ºè¯­ä¹‰é‡è¦æ€§è¾ƒé«˜çš„ Patch, ä½œè€…æ˜¯å°†ä¸åŒå±‚çš„ Cls-Token Attention é€šè¿‡ä¸‹é¢çš„æ–¹å¼èåˆèµ·æ¥ï¼š

$$
\overline{\mathbf{a}}_{k}=\beta \cdot \overline{\mathbf{a}}_{k-1}+(1-\beta) \cdot \mathbf{a}_{k}^{0}
$$

è¿™é‡Œçš„ $$k$$ è¡¨ç¤ºçš„æ˜¯ç¬¬ $$k$$ å±‚ï¼Œ $$\beta$$ è¡¨ç¤ºçš„ç§»åŠ¨å¹³å‡å‚æ•°ã€‚
ä½¿ç”¨ Class AttentionæŒ‡ç¤º Patch çš„è¯­ä¹‰é‡è¦æ€§åœ¨ä¹‹å‰çš„å·¥ä½œä¸­æœ‰ä½¿ç”¨ï¼Œå› æ­¤ä½œè€…è¿™é‡Œè¿˜å¼ºè°ƒäº†ä¸åŒã€‚ã€‚ã€‚ã€‚

- **Fine Inference Stage**

å¦‚æœåœ¨ä¸Šä¸€é˜¶æ®µçš„é¢„æµ‹ç»“æœç½®ä¿¡åº¦ä¸é«˜äºé˜ˆå€¼ $$\eta$$ æ—¶ï¼Œå°±è¦è¿›å…¥ç»†ç²’åº¦é¢„æµ‹é˜¶æ®µï¼Œè¿™ä¸€æ­¥ä¼šé€‰æ‹©è¯­ä¹‰é‡è¦æ€§é«˜çš„Patchï¼Œç„¶ååˆ’åˆ†æˆ Size æ›´å°çš„ Patchï¼Œ ä¸ºäº†ç„¶åå°†ä¸Šä¸€é˜¶æ®µçš„Patch ç‰¹å¾ä¹Ÿç”¨åˆ°è¿™ä¸€é˜¶æ®µä¸­ï¼Œä½œè€…ç§°å…¶ä¸ºç‰¹å¾é‡ç”¨ï¼Œæ“ä½œæ¯”è¾ƒç®€å•å¦‚ä¸‹å›¾ï¼š

<div align=center><img src="http://tva1.sinaimg.cn/large/007d2DYjly1h2p4tvxr4sj312t0l4nap.jpg" width="600"></div>



### ğŸ¦– å®éªŒ

- åœ¨ImageNet-1Kä¸Šçš„åˆ†ç±»æ•ˆæœæ¯”è¾ƒ
<div align=center><img src="http://tva1.sinaimg.cn/large/007d2DYjly1h2p4usbc0vj313s0o80z6.jpg" width="600"></div>


