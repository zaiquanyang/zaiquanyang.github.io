---
layout: post
title: 实例分割SOLO系列介绍
tags: 实例分割
---

# SOLO: Segmenting Objects by Locations ECCV_2020

- 概要

  实例分割的一般做法是两种：

  - 一种是`top-down`，既先检测 `bbox`，后在每个`bbox`中进行`mask`的分割，例如`Mask R-CNN`
  - 第二种为`bottom-up`做法，先分割出每一个像素，再进行归类。

  不同于上面两种，`SOLO`是属于`box free`的做法，而且能够直接进行分割实例。

  [arxiv](https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1912.04488) 

  [github 基于mmdet实现](https://link.zhihu.com/?target=https%3A//github.com/WXinlong/SOLO)

- 模型框架

  <img src="D:\Document\Typora_files\Images\image-20220309210330550.png" alt="image-20220309210330550" style="zoom: 67%;" />

  - 类别与掩码双分支预测结构

    整个框架的核心思想是将实例分割任务分成预测**某一位置上的实体类别、实体掩码**两个问题，分别对应的语义分类头和掩码预测头。

    具体的做法是把输入大小为`H x W`的图像像`YOLO`那样划分成`S x S`个格子(`grid cell`)，当`gt mask`的中心坐标落到哪个格子上，那么**预测头的对应该格子的部分**就负责预测该实例，包括其语义类别和`mask`。

    对于图中的马来说，当它落到格子`(i,j)`时，那么语义分类分支`Category branch`就会预测位置为`(i,j)`处的类别，假设类别数目一共为`C`，则语义分类分支的输出为`S x S x C`。特别的对于`Mask Branch`来说，`SOLO`是对每个格子安排专门安排了一个通道负责预测掩码，因此负责预测的位于第`i x S + j`个通道。

    

    实际上对于每个实例`instance`，作者先做了一步尺度缩放$\epsilon=0.5$, 缩小的`instance`覆盖的格子都要负责预测该实例，这样做可以增加正样本的数目，也就是说最后预测的`mask`输出会有冗余，最后会通过`NMS`保留其中一部分。

  - **`CoordConv`**

    实例分割任务不同于分类任务需要获取对位置敏感或者说平移等变性的特征，因此作者简单地采用了文章[17]的做法在特征前面加上了二维坐标信息，实际上特征图就变成了`256 + 2`。

  - **`Decoupled head`**

    由于`mask`分支预测 `S x S` 个通道, 如果`grid cell` 设置过多的话，计算量会过于庞大。因此论文提出`Decoupled head`的改进方式。具体见下图，将`mask`分支更进一步拆分为`X`方向和`Y`方向两个分支，每一个分支的通道数为`S` 。将两个分支按照`element-wise`的方式进行相乘获取`mask`输出，这样预测通道由原来的 `S x S` 变为了 `2 x S` 个，实验发现精度并没有明显的损失。此时想要获取第 `k`个格子预测的`mask`，只需要将`X`分支的第`i`个结果与`Y`分支的第`j`个结果相乘即可。

- `Loss`

  和大部分的实例分割一样，`SOLO`的损失包括类别预测损失和`mask`预测损失，其中实验表明`Dice Loss`适合计算`Mask`预测损失，可能也是因为`SOLO`在预测过程中包含了较多的负样本，而`Dice Loss`可以有效缓解背景区域这些负样本对损失的淹没影响[Dice为什么能够解决正负样本不平衡的问题](https://zhuanlan.zhihu.com/p/269592183)。