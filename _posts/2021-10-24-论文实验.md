---
<!-- layout: post -->
title: 论文实验记录
tags: 实验记录
---



### 1. C2F_ZSL_CVPR

思路整理：

#### 1.1 不同Fine-tune方式(V2S, S2V, Vanilla-Label)得到的特征方差可视化实验

**`V2S`和`S2V`数据点近邻分布的斜度比较**

  - `V2S`的特征`K`近邻分布斜度要大于`S2V`，但是其映射到`S`空间后的`K`近邻分布斜度可能会小于`S2V`的(有待进一步可视化验证)。

**为什么`S2V`比 `V2S`的泛化能力差？**
  - 首先`S2V`是在一个更高维的空间中进行度量学习，`S2V`则是在一个低维空间中进行度量学习，那么根据之前的研究工作，
    我们可以想到`S2V`会产生比较严重的`hubness`问题，导致模型的分类性能降低，为了取得更好的训练结果，随着训练的不断深入，
    模型就会过拟合到输入的一些噪声性特征，导致模型的泛化能力下降。
  - 直觉上我觉得是因为`S2V`在度量学习的时候考虑到了每个维度或者`pattern`，尽管这些维度有相当部分其实是任务无关的，
    这就导致了最后的特征嵌入会糅杂进较多的噪声特征，一定程度上淹没了有意义的语义特征，弱化了特征的可泛化性。
  - 实验结果验证如下
    `train_seen`上`S2V`的方差是更小的,  但是在`test_seen`上`S2V`似乎更大一些, 尤其是在`test_unseen`上`S2V`的方差更为明显
    再看一下随着epoch的增加，`S2V`在`test-unseen`上的方差变化, 发现其方差在开始的epoch会逐步减小，但是随着训练的进行方差反而增加,
    `V2S`在`test-unseen`上的方差变化则一直都是逐渐降低的.

    <div align=center>
      <img src="https://i.postimg.cc/xTQ3Dz9N/VAR-2.png" width="200">
      <img src="https://i.postimg.cc/vTr7xQtm/VAR-1.png" width="300">
      <img src="https://i.postimg.cc/Kv5rZ8Yq/VAR-3.png" width="300">
    </div>

    <div align=center><img src="https://i.postimg.cc/DZsLR2Dc/VAR-4.png" width="300"><img src="https://i.postimg.cc/Fz434MXX/VAR-5.png" width="300"></div>



#### 待做实验一

- 实验内容


- 实验目的

- 实验命令

  ```


  ```
